<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Linearity and normality</title>

<script src="site_libs/header-attrs-2.6/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Applied Regression in R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lecture materials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Lecture Notes</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="01_intro.html">Introduction - goals of regression analysis</a>
        </li>
        <li>
          <a href="02_simple_linear_regression.html">Simple linear regression</a>
        </li>
        <li class="dropdown-header">Multiple linear regression</li>
        <li class="dropdown-header">Model fit</li>
        <li class="dropdown-header">Ploting regression models, marginal effects</li>
        <li>
          <a href="06_assumptions.html">Assumptions of linear models</a>
        </li>
        <li>
          <a href="06_diagnostics.html">Regression diagnostics</a>
        </li>
        <li class="dropdown-header">Linearity and normality</li>
        <li class="dropdown-header">Homoscedasticity</li>
        <li class="dropdown-header">Exporting results and multiple models</li>
        <li class="dropdown-header">Prediction and regularization</li>
        <li class="dropdown-header">Missing values imputations</li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Lecture Slides</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="01_slides_intro.html">Introduction - goals of regression analysis</a>
        </li>
        <li>
          <a href="02_slides_simple_linear_regression.html">Simple linear regression</a>
        </li>
        <li class="dropdown-header">Multiple linear regression</li>
        <li class="dropdown-header">Model fit</li>
        <li class="dropdown-header">Ploting regression models, marginal effects</li>
        <li class="dropdown-header">Assumptions of linear models</li>
        <li class="dropdown-header">Regression diagnostics</li>
        <li class="dropdown-header">Linearity and normality</li>
        <li class="dropdown-header">Homoscedasticity</li>
        <li class="dropdown-header">Exporting results and multiple models</li>
        <li class="dropdown-header">Prediction and regularization</li>
        <li class="dropdown-header">Missing values imputations</li>
      </ul>
    </li>
  </ul>
</li>
<li>
  <a href="completion_requirements.html">Completion Requirements</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Data and literature
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="course_data.html">Course data</a>
    </li>
    <li>
      <a href="literature.html">Literature</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://ksoc.ff.cuni.cz/">Department website</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Linearity and normality</h1>

</div>


<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## -- Attaching packages --------------------------------------- tidyverse 1.3.0 --</code></pre>
<pre><code>## &lt;U+221A&gt; ggplot2 3.3.3     &lt;U+221A&gt; purrr   0.3.4
## &lt;U+221A&gt; tibble  3.0.6     &lt;U+221A&gt; dplyr   1.0.4
## &lt;U+221A&gt; tidyr   1.1.2     &lt;U+221A&gt; stringr 1.4.0
## &lt;U+221A&gt; readr   1.4.0     &lt;U+221A&gt; forcats 0.5.1</code></pre>
<pre><code>## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(splines)
library(lspline)
library(ggeffects)

vote = read.csv(&quot;data/parl_vote_2017.csv&quot;)
un = read.table(&quot;data/UnitedNations.txt&quot;)</code></pre>
<p>In this chapter, we will look into ways of modeling nonlinear relationship, as well solving the problem of nonconstant variance.</p>
<div id="modeling-nonlinearity" class="section level1">
<h1>Modeling nonlinearity</h1>
<p>There are many ways one could go around modeling nonlinear relationship through regression models. We will present three basic, which are common and easy to implement: a) categorization b ) polynomial functions and c) splines, also called piecewise polynomials.</p>
<p>For demonstration, we will use data from the eight round of the European Social Survey. More specificaly, data on voter turnouver per age group in the last pairlamentary elections in the Czech republic. Just by ploting the data, we can notice a nonlinear relationship between voter turnout and age:</p>
<pre class="r"><code>ggplot(data = vote, aes(x = agea, y = vote)) +
  geom_point() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(x = &quot;Age&quot;, y = &quot;% of respondents who attended the elections&quot;)</code></pre>
<div class="figure">
<img src="07_linearity_and_normality_files/figure-html/age-vs-vote-1.png" alt="Age vs voter turnout" width="672" />
<p class="caption">
Age vs voter turnout
</p>
</div>
<p>We can reach the same conclusion by fitting a linear model and checking the residual plot:</p>
<pre class="r"><code>mod_linear = lm(vote ~ agea, data = vote)

plot(mod_linear, which = 1)</code></pre>
<p><img src="07_linearity_and_normality_files/figure-html/linear-mod-example-1.png" width="672" /></p>
<p>While the sample size is relatively small, the residual plot suggests that simple linear regression may not give us the full picture on the relationship between age and voter turnout.</p>
<div id="categorization" class="section level2">
<h2>Categorization</h2>
<p>THe easiest and by far the most popular way to model nonlinear relationship between variables is to simply categorize the independent variable. The categorization can be done in multiple ways and choice is mostly arbitrary. The <code>ggplot2</code> is particulary helpful, as it offers three categorization function: <code>cut_interval()</code>, <code>cut_number()</code> and <code>cut_width()</code>.</p>
<p>The function <code>cut_interval()</code> discretize a metric variable into <code>n</code> group of equal range. For example, to categorize age into three groups with equal range and plot the model:</p>
<pre class="r"><code>vote$agea_interval = cut_interval(vote$agea, n = 3)

mod_interval = lm(vote ~ agea_interval, data = vote)

plot(ggeffect(mod_interval))</code></pre>
<pre><code>## $agea_interval</code></pre>
<p><img src="07_linearity_and_normality_files/figure-html/cut-interval-example-1.png" width="672" /></p>
<p>As we can see, the age variable was cut into three groups, each with range of 24.65. Alternatively we can use the <code>cut_number()</code> function to categorize age into <code>n</code> groups with (aproximately) the same number of observations:</p>
<pre class="r"><code>vote$agea_number = cut_number(vote$agea, n = 3)

mod_number = lm(vote ~ agea_number, data = vote)

plot(ggeffect(mod_number))</code></pre>
<pre><code>## $agea_number</code></pre>
<p><img src="07_linearity_and_normality_files/figure-html/cut-number-example-1.png" width="672" /></p>
<p>The third option is to discretise the metric variable into categories of equal <code>width</code>. This can be done using the <code>cut_width()</code> function:</p>
<pre class="r"><code>vote$agea_width = cut_width(vote$agea, width  = 30)

mod_width = lm(vote ~ agea_width, data = vote)

plot(ggeffect(mod_width))</code></pre>
<pre><code>## $agea_width</code></pre>
<p><img src="07_linearity_and_normality_files/figure-html/cut-width-example-1.png" width="672" /></p>
<p>The last option is to base the categorization of our data not on the properties of our sample, such as range or quantiles, but determine our the categories according to a theory. For example, in the context of political behavior, people are often categorized into three cohort: a) age 25 and younger b) 26 to 55 years and c) 56 or more.</p>
<pre class="r"><code>vote$agea_theory = case_when(
                             vote$agea &lt;= 25 ~ &quot;25 or less&quot;,
                             vote$agea &lt;= 55 ~ &quot;26 to 55&quot;,
                             vote$agea &gt; 55 ~ &quot;55 or more&quot;)

mod_theory = lm(vote ~ agea_theory, data = vote)

plot(ggeffect(mod_theory))</code></pre>
<pre><code>## $agea_theory</code></pre>
<p><img src="07_linearity_and_normality_files/figure-html/cut-theory-example-1.png" width="672" /></p>
<p>While modeling nonlinear relationships using categorization of metric variables is conveniently easy, it also suffer from a number of problems. <span class="citation">Harrell (2001)</span> provides a list of major problems, among others:</p>
<ul>
<li><p>Estimated values will have reduced precision, and associated tests will have reduced power</p></li>
<li><p>Categorization assumes that the relationship between the predictor and the response is flat within intervals</p></li>
<li><p>Categorization assumes that there is a discontinuity in response as interval boundaries are crossed.</p></li>
<li><p>Cutpoints are arbitrary and manipulatable; cutpoints can be found that can result<br />
in both positive and negative associations</p></li>
</ul>
<p>For these and more reasons described by Harrel, the categorization of interval variables should be in most cases avoided.</p>
</div>
<div id="polynomials" class="section level2">
<h2>Polynomials</h2>
<p>Another option for modeling nonlinearity is to use polynomial functions. Polynomials functions are ones which include an exponent of a variable. An example of a regression model with polynomial function would be</p>
<p><span class="math display">\[
vote = \beta_0 + \beta_1*age + \beta_2*age^2
\]</span></p>
<p>with <span class="math inline">\(age\)</span> being taken to the power of two. This effectively replaces the assumption that the relation between vote and age is a straight line with the assumption that the relationship has a shape of a parabola. We could also use higher order exponents to model increasingly flexible relationships.</p>
<p>There are two types of polynomials - raw polynomials and orthogonal ones. The raw polynomial is simple the variable taken to the power of <em>k</em>. To use second order raw polynomial in a regression model we can write:</p>
<pre class="r"><code>lm(vote ~ poly(agea, 2, raw = TRUE), data = vote)</code></pre>
<p>or alternatively:</p>
<pre class="r"><code>lm(vote ~ agea + I(agea^2), data = vote)</code></pre>
<p>Note that both give the same result.</p>
<p>On the other hand, orthogonal polynomials are computed in such a way that the variable <span class="math inline">\(x^k\)</span> is uncorrelated, i.e. orthogonal, to the original variable <span class="math inline">\(x\)</span>. To compute a second order orthogonal polynomial:</p>
<pre class="r"><code>lm(lm(vote ~ poly(agea, 2), data = vote))</code></pre>
<pre><code>## 
## Call:
## lm(formula = lm(vote ~ poly(agea, 2), data = vote))
## 
## Coefficients:
##    (Intercept)  poly(agea, 2)1  poly(agea, 2)2  
##         0.5769          1.0395         -0.4469</code></pre>
<p>Which of these two types of polynomials should we choose? Both types of polynomials lead to the same model in the terms of fit and predictions. The advantage of raw polynomials is that the regression coefficients have the traditional interpretation of <em>change in</em> <span class="math inline">\(y\)</span>, when <span class="math inline">\(x\)</span> is changed by one and <span class="math inline">\(x^k\)</span> is fixed at zero. However, the interpretation of variables transformed in such way is difficult no matter what. The major advantage of the orthogonal polynomials is that we can compute the proportion variance explained by each variable and therefore assess its contribution to the predictive power. If our goal is to interpret the relationship between variables visually through the marginal effects plots, or if only include the variable as a control, the choice of polynomial type does not matter.</p>
<p>Since we nonlinear relationship are best interpreted visually, we prefer orthogonal polynomials. We can visualize a polynomial regression model using the <code>ggeffects</code> package:</p>
<pre class="r"><code>mod_poly = lm(vote ~ poly(agea, 2), data = vote)

plot(ggeffect(mod_poly))</code></pre>
<pre><code>## $agea</code></pre>
<p><img src="07_linearity_and_normality_files/figure-html/poly-example-1.png" width="672" /></p>
<p>While polynomials are often a better option than the categorization approach, they are not without problems. The main problem is that polynomial functions are non local <span class="citation">Harrell (2001)</span>, which means that data in one region can strongly influence predicted values in other regions, especially those with small number of observations. This means that the polynomial regression curves often get “wiggly” and overly curved at the ends. Therefore, polynomial regression tend to provide a good fit only in the regions with most data and are often bad at extrapolation. Polynomials are also bad at modeling relationships that are nonlinear only in certain regions and linear in other. For example, a second order polynomial leads by definition to the shape of a parabola and the regression has to predict a curve along the entire range of data. This means that polynomials are bad at modeling relationship that tend to level of at same point. These problems are especially pronounced with higher degrees polynomials.</p>
<p>In the graph below, we can see, how polynomials can be particularly bad at modeling relationships, that are nonlinear in some regions and linear in others. The blue line is for second order polynomial, the blue one for third order one.</p>
<div class="figure">
<img src="07_linearity_and_normality_files/figure-html/poly-wiggle-1.png" alt="Problem with fitting polynomials to asymptotic data" width="672" />
<p class="caption">
Problem with fitting polynomials to asymptotic data
</p>
</div>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-fox2015" class="csl-entry">
Fox, John. 2015. <em>Applied Regression Analysis and Generalized Linear Models</em>. Third edition. Los Angeles: SAGE Publications, Inc.
</div>
<div id="ref-harrellRegressionModelingStrategies2001" class="csl-entry">
Harrell, Frank. 2001. <em>Regression Modeling Strategies: With Applications to Linear Models, Logistic Regression, and Survival Analysis</em>. Springer Series in Statistics. New York: Springer-Verlag. <a href="https://doi.org/10.1007/978-1-4757-3462-1">https://doi.org/10.1007/978-1-4757-3462-1</a>.
</div>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
