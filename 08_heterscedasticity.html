<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Heteroskedasticity</title>

<script src="site_libs/header-attrs-2.7/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>




<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Applied Regression in R</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Lectures
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Lecture Notes</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="01_intro.html">Introduction - goals of regression analysis</a>
        </li>
        <li>
          <a href="02_simple_linear_regression.html">Simple linear regression</a>
        </li>
        <li>
          <a href="03_multiple_linear_regression.html">Multiple linear regression</a>
        </li>
        <li class="dropdown-header">Ploting regression models, marginal effects</li>
        <li>
          <a href="05_model_fit.html">Model fit</a>
        </li>
        <li>
          <a href="06_assumptions.html">Assumptions of linear models</a>
        </li>
        <li>
          <a href="06_diagnostics.html">Regression diagnostics</a>
        </li>
        <li>
          <a href="07_linearity_and_normality.html">Linearity and normality</a>
        </li>
        <li class="dropdown-header">Homoscedasticity</li>
        <li class="dropdown-header">Exporting results and multiple models</li>
        <li class="dropdown-header">Prediction and regularization</li>
        <li class="dropdown-header">Missing values imputations</li>
      </ul>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">Lecture Slides</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="01_slides_intro.html">Introduction - goals of regression analysis</a>
        </li>
        <li>
          <a href="02_slides_simple_linear_regression.html">Simple linear regression</a>
        </li>
        <li>
          <a href="03_slides_multiple_linear_regression.html">Multiple linear regression</a>
        </li>
        <li>
          <a href="04_slides_model_visualization.html">Ploting regression models, marginal effects</a>
        </li>
        <li>
          <a href="05_slides_model_fit.html">Model fit</a>
        </li>
        <li>
          <a href="06_slides_model_assumptions.html">Assumptions of linear models and diagnostics</a>
        </li>
        <li>
          <a href="07_slides_nonlinearity.html">Linearity</a>
        </li>
        <li class="dropdown-header">Homoscedasticity</li>
        <li class="dropdown-header">Exporting results and multiple models</li>
        <li class="dropdown-header">Prediction and regularization</li>
        <li class="dropdown-header">Missing values imputations</li>
      </ul>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Practice
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_intro_R_excercises.html">Introduction - goals of regression analysis</a>
    </li>
    <li>
      <a href="02_simple_linear_regression_excercises.html">Simple linear regression</a>
    </li>
    <li>
      <a href="03_multiple_linear_regression_excercises.html">Multiple linear regression</a>
    </li>
    <li>
      <a href="035_multiple_linear_regression_excercises_2.html">Interactions</a>
    </li>
    <li>
      <a href="04_model_visualization_exercises.html">Ploting regression models, marginal effects</a>
    </li>
    <li>
      <a href="05_model_fit_exercises.html">Model fit</a>
    </li>
    <li class="dropdown-header">Assumptions of linear models</li>
    <li class="dropdown-header">Regression diagnostics</li>
    <li class="dropdown-header">Linearity and normality</li>
    <li class="dropdown-header">Homoscedasticity</li>
    <li class="dropdown-header">Exporting results and multiple models</li>
    <li class="dropdown-header">Prediction and regularization</li>
    <li class="dropdown-header">Missing values imputations</li>
  </ul>
</li>
<li>
  <a href="completion_requirements.html">Completion Requirements</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Materials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="course_data.html">Course data</a>
    </li>
    <li>
      <a href="literature.html">Literature</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://ksoc.ff.cuni.cz/">Department website</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Heteroskedasticity</h1>

</div>


<p>In this section, we will describe one of the approaches to dealing with nonconstant residual variance, namely robust standard errors. We will demonstrate this on the data on a model predicting infant mortality per 1000 of live births (<code>infantMortality</code>) by total fertility rate in a country (<code>tfr</code>). The data originaly came from the United Nations:</p>
<pre class="r"><code>mod1 = lm(infantMortality ~ tfr, data = un)</code></pre>
<p>We can check the assumption of homoscedasticity, i.e. the assumption that residuals have equal variance for all values of the independet variable, using a diagnostic residual plot:</p>
<pre class="r"><code>plot(mod1, which = 1)</code></pre>
<p><img src="08_heterscedasticity_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>From the plot above, we can see that the assumption of homoscedasticity has been violated, as the variance of residuals increases together with the predicted values of the dependent variables. This has two consequences: 1) The estimate of the regression coefficient will be less efficient, i.e. we will require more observations to reach the same level of precision, compared to model that fulfills the homoscedasticity assumption. 2) More concernedly, the standard errors estimates will be biased, leading to systematically under/overestimated confidence of our results.</p>
<div id="classic-standard-errors" class="section level1">
<h1>Classic Standard errors</h1>
<p>To see why homoscedasticity may be a problem, let’s see how classic standard errors for regression coefficients are computed. Formally, the classic standard error of a regression coefficient is:</p>
<p><span class="math display">\[
SE_\beta = \frac{\sigma^2 \sum(x_i - \bar{x})^2}{[\sum(x_i - \bar{x})^2]^2} = \frac{\sigma^2}{\sum(x_i - \bar{x})^2}
\]</span></p>
<p>Where <span class="math inline">\(\sigma^2\)</span> is the variance of residuals, also known as the mean square error, and <span class="math inline">\((x-\bar{x})^2\)</span> is total sum of squares, i.e. the sum of squared differences between the observed values of the independent variable and their mean. The important thing to notice is that the variance of residuals (<span class="math inline">\(\sigma^2\)</span>) is a constant, a single value applied for all values of the independent variable.</p>
<p>The reason why we compute the variance of all residuals regardless of the values of the independent variable is because of the fact that if several groups of data have the same variance, than all the data together will have also the same variance. For example, consider the following two vectors of numbers:</p>
<p><code>vector 1 = 0.8551603, -0.1219514,0.7444561, -1.6354559, 0.1577908</code></p>
<p><code>vector 2 = -0.00542261, -1.71423480, 0.51218859, 0.79087341, 0.41659541</code></p>
<p>The variance of of the first vector is 0.8. The second vector has the same variance (barring some rounding errors) of 0.8. If we were to combine the two vectors together:</p>
<p><code>vector3 = 0.8551603, -0.1219514,0.7444561, -1.6354559, 0.1577908, -0.00542261, -1.71423480, 0.51218859, 0.79087341, 0.41659541</code></p>
<p>and then compute the variance of all, we would find that all the values together have the same variance as both groups separately, that is 0.8.</p>
<p>This provides an immensely useful computational shortcut, which allowed for computation of linear regression models long before computers become prevalent. By computing the variance of all residuals together, we will know variance of residuals for every value of the independent variable. However, as mentioned, this is only true if the variance of residuals across all values of the independent variable is equal, i.e. if the assumption of homoscedasticity is met.</p>
</div>
<div id="robust-standard-errors" class="section level1">
<h1>Robust standard errors</h1>
<p>What if the variance of residuals differ, based on the value of the independent variable?</p>
<p>Consider a different two vectors of numbers:</p>
<p><code>vector 1 = 0.05329121, 0.47450291, 0.68218495, -0.92324431, -0.28673476</code></p>
<p><code>vector 2 = -1.04618281, 3.36022661, -1.62755560, -0.76224781, 0.07575961</code></p>
<p>The variance of the first vector is 0.33, while the variance of the second one is 3.12. Since those two vectors have different variances, it is no surprise that the variance of all the values together is not equal to any of the two groups (in this case, it is 1.72). Consequently, if the assumption of the assumption of homoscedasticity is violated, we cannot infer variance of residuals for any level of the independent variable by simply computing the variance of all residuals.</p>
<p>What then? The answer is surprisingly straightforward. If knowing the total variance is not enough, we will have compute the variance of residuals for all values of the independent variable, one by one. The formula for the standard error of a regression coefficient becomes <span class="citation">(Wooldridge, 2015, p. 245)</span> :</p>
<p><span class="math display">\[
SE_\beta = \frac{\sum(x_i - \bar{x})^2*\sigma_i^2}{[\sum(x_i - \bar{x})^2]^2}
\]</span> Notice that the only thing that changed from the previous formula is that we no longer computes the sum of squares (<span class="math inline">\(\sum(x_i - \bar{x})^2\)</span>) and then multiple it by the variance of residuals. Instead we compute the variance of residuals for every level of the independent variable separately (<span class="math inline">\(\sigma_i^2\)</span>). This way of computing standard error is known as the robust standard errors, also known as heteroscedastic standard errors or sandwich errors. Note that if the variance of residuals is actually the same for all levels of independent variable, i.e. if the residuals are actually homoscedastic, both formulas give the same result.</p>
<div id="refs" class="references csl-bib-body hanging-indent" line-spacing="2">
<div id="ref-wooldridge2015" class="csl-entry">
Wooldridge, J. M. (2015). <em>Introductory econometrics: A modern approach</em> (006 edition). Cengage Learning.
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
